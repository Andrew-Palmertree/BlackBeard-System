{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b81c38da",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Load YOLO model\n",
    "net = cv2.dnn.readNet(\"yolov3.weights\", \"yolov3.cfg\")\n",
    "\n",
    "# Load COCO class names from the coco.names file\n",
    "with open(\"coco.names\", \"r\") as f:\n",
    "    classes = f.read().strip().split('\\n')\n",
    "\n",
    "# Initialize the webcam\n",
    "cap = cv2.VideoCapture(0)  # 0 represents the default camera (you can change it if you have multiple cameras)\n",
    "\n",
    "# Set a minimum confidence threshold\n",
    "confidence_threshold = 0.3\n",
    "\n",
    "# Initialize variables to store bounding box information\n",
    "bounding_boxes = []\n",
    "\n",
    "# Initialize a variable to keep track of the last time an object was checked\n",
    "last_check_time = time.time()\n",
    "\n",
    "# Maximum number of unique boxes to display\n",
    "max_boxes = 10\n",
    "\n",
    "# Dictionary to track unique objects\n",
    "unique_objects = {}\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Calculate the time since the last object check\n",
    "    elapsed_time = time.time() - last_check_time\n",
    "\n",
    "    if elapsed_time >= 1.0:  # Check for objects every 1 second\n",
    "        # Prepare the frame for detection (e.g., resizing, normalization)\n",
    "        blob = cv2.dnn.blobFromImage(frame, 1/255.0, (416, 416), swapRB=True, crop=False)\n",
    "\n",
    "        # Set the input to the YOLO model\n",
    "        net.setInput(blob)\n",
    "\n",
    "        # Get the output layer names\n",
    "        layer_names = net.getUnconnectedOutLayersNames()\n",
    "\n",
    "        # Forward pass\n",
    "        detections = net.forward(layer_names)\n",
    "\n",
    "        # Clear the existing bounding boxes and unique objects\n",
    "        bounding_boxes = []\n",
    "        unique_objects = {}\n",
    "\n",
    "        # Process the detections and store the bounding box information\n",
    "        for detection in detections:\n",
    "            for obj in detection:\n",
    "                scores = obj[5:]\n",
    "                class_id = np.argmax(scores)\n",
    "                confidence = scores[class_id]\n",
    "\n",
    "                if confidence > confidence_threshold:\n",
    "                    center_x = int(obj[0] * frame.shape[1])\n",
    "                    center_y = int(obj[1] * frame.shape[0])\n",
    "                    width = int(obj[2] * frame.shape[1])\n",
    "                    height = int(obj[3] * frame.shape[0])\n",
    "\n",
    "                    # Calculate coordinates for drawing the bounding box\n",
    "                    x = int(center_x - width / 2)\n",
    "                    y = int(center_y - height / 2)\n",
    "\n",
    "                    # Determine if the object is square (close to aspect ratio 1)\n",
    "                    is_square = abs(1 - width / height) < 0.1\n",
    "\n",
    "                    # Generate a unique identifier for this object\n",
    "                    obj_id = f\"{classes[class_id]}_{x}_{y}\"\n",
    "\n",
    "                    # Check if this object is unique and has not been seen before\n",
    "                    if obj_id not in unique_objects:\n",
    "                        # Store the bounding box information\n",
    "                        if is_square:\n",
    "                            # Treat square-like objects as boxes\n",
    "                            bounding_boxes.append((x, y, width, height, class_id, confidence))\n",
    "\n",
    "                        # Record that this object is unique and has been seen\n",
    "                        unique_objects[obj_id] = True\n",
    "\n",
    "        # Sort the bounding boxes by confidence (highest to lowest)\n",
    "        bounding_boxes.sort(key=lambda box: box[5], reverse=True)\n",
    "\n",
    "        # Display a maximum of three unique boxes\n",
    "        bounding_boxes = bounding_boxes[:max_boxes]\n",
    "\n",
    "        # Update the last check time\n",
    "        last_check_time = time.time()\n",
    "\n",
    "    # Check if a person and a box are present together\n",
    "    person_detected = False\n",
    "    box_detected = False\n",
    "\n",
    "    for x, y, width, height, class_id, confidence in bounding_boxes:\n",
    "        if classes[class_id] == 'person':\n",
    "            person_detected = True\n",
    "        elif classes[class_id] == 'box':\n",
    "            box_detected = True\n",
    "\n",
    "    # Determine if a person and a box are present together\n",
    "    person_and_box_detected = person_detected and box_detected\n",
    "\n",
    "    # Draw bounding boxes on the frame\n",
    "    for x, y, width, height, class_id, confidence in bounding_boxes:\n",
    "        label = f\"{classes[class_id]}: {confidence:.2f}\"\n",
    "        cv2.rectangle(frame, (x, y), (x + width, y + height), (0, 255, 0), 2)\n",
    "        cv2.putText(frame, label, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "    # Display the status of person, box, and person-and-box together at the top of the frame\n",
    "    status = f\"Person: {person_detected}, Box: {box_detected}, Person and Box: {person_and_box_detected}\"\n",
    "    cv2.putText(frame, status, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "    # Display the result\n",
    "    cv2.imshow(\"Webcam Object Detection\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == 27:  # Press 'Esc' key to exit\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd21e6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Load YOLO model\n",
    "net = cv2.dnn.readNet(\"yolov3.weights\", \"yolov3.cfg\")\n",
    "\n",
    "# Load COCO class names from the coco.names file\n",
    "with open(\"coco.names\", \"r\") as f:\n",
    "    classes = f.read().strip().split('\\n')\n",
    "\n",
    "# Initialize the webcam\n",
    "cap = cv2.VideoCapture(0)  # 0 represents the default camera (you can change it if you have multiple cameras)\n",
    "\n",
    "# Set a minimum confidence threshold\n",
    "confidence_threshold = 0.3\n",
    "\n",
    "# Initialize variables to store bounding box information\n",
    "bounding_boxes = []\n",
    "\n",
    "# Initialize a variable to keep track of the last time an object was checked\n",
    "last_check_time = time.time()\n",
    "\n",
    "# Maximum number of unique boxes to display\n",
    "max_boxes = 30\n",
    "\n",
    "# Dictionary to track unique objects\n",
    "unique_objects = {}\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Calculate the time since the last object check\n",
    "    elapsed_time = time.time() - last_check_time\n",
    "\n",
    "    if elapsed_time >= 1.0:  # Check for objects every 1 second\n",
    "        # Prepare the frame for detection (e.g., resizing, normalization)\n",
    "        blob = cv2.dnn.blobFromImage(frame, 1/255.0, (416, 416), swapRB=True, crop=False)\n",
    "\n",
    "        # Set the input to the YOLO model\n",
    "        net.setInput(blob)\n",
    "\n",
    "        # Get the output layer names\n",
    "        layer_names = net.getUnconnectedOutLayersNames()\n",
    "\n",
    "        # Forward pass\n",
    "        detections = net.forward(layer_names)\n",
    "\n",
    "        # Clear the existing bounding boxes and unique objects\n",
    "        bounding_boxes = []\n",
    "        unique_objects = {}\n",
    "\n",
    "        # Process the detections and store the bounding box information\n",
    "        for detection in detections:\n",
    "            for obj in detection:\n",
    "                scores = obj[5:]\n",
    "                class_id = np.argmax(scores)\n",
    "                confidence = scores[class_id]\n",
    "\n",
    "                if confidence > confidence_threshold:\n",
    "                    center_x = int(obj[0] * frame.shape[1])\n",
    "                    center_y = int(obj[1] * frame.shape[0])\n",
    "                    width = int(obj[2] * frame.shape[1])\n",
    "                    height = int(obj[3] * frame.shape[0])\n",
    "\n",
    "                    # Calculate coordinates for drawing the bounding box\n",
    "                    x = int(center_x - width / 2)\n",
    "                    y = int(center_y - height / 2)\n",
    "\n",
    "                    # Determine if the object is square (close to aspect ratio 1)\n",
    "                    is_square = abs(1 - width / height) < 0.1\n",
    "\n",
    "                    # Generate a unique identifier for this object\n",
    "                    obj_id = f\"{classes[class_id]}_{x}_{y}\"\n",
    "\n",
    "                    # Check if this object is unique and has not been seen before\n",
    "                    if obj_id not in unique_objects:\n",
    "                        # Store the bounding box information\n",
    "                        if is_square and classes[class_id] == 'phone':\n",
    "                            # Treat square-like objects as phones\n",
    "                            bounding_boxes.append((x, y, width, height, class_id, confidence))\n",
    "\n",
    "                        # Record that this object is unique and has been seen\n",
    "                        unique_objects[obj_id] = True\n",
    "\n",
    "        # Sort the bounding boxes by confidence (highest to lowest)\n",
    "        bounding_boxes.sort(key=lambda box: box[5], reverse=True)\n",
    "\n",
    "        # Display a maximum of three unique boxes\n",
    "        bounding_boxes = bounding_boxes[:max_boxes]\n",
    "\n",
    "        # Update the last check time\n",
    "        last_check_time = time.time()\n",
    "\n",
    "    # Check if a person and a phone are present together\n",
    "    person_detected = False\n",
    "    phone_detected = False\n",
    "\n",
    "    for x, y, width, height, class_id, confidence in bounding_boxes:\n",
    "        if classes[class_id] == 'person':\n",
    "            person_detected = True\n",
    "        elif classes[class_id] == 'phone':\n",
    "            phone_detected = True\n",
    "\n",
    "    # Determine if a person and a phone are present together\n",
    "    person_and_phone_detected = person_detected and phone_detected\n",
    "\n",
    "    # Draw bounding boxes on the frame\n",
    "    for x, y, width, height, class_id, confidence in bounding_boxes:\n",
    "        label = f\"{classes[class_id]}: {confidence:.2f}\"\n",
    "        cv2.rectangle(frame, (x, y), (x + width, y + height), (0, 255, 0), 2)\n",
    "        cv2.putText(frame, label, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "    # Display the status of person, phone, and person-and-phone together at the top of the frame\n",
    "    status = f\"Person: {person_detected}, Phone: {phone_detected}, Person and Phone: {person_and_phone_detected}\"\n",
    "    cv2.putText(frame, status, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "    # Display the result\n",
    "    cv2.imshow(\"Webcam Object Detection\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == 27:  # Press 'Esc' key to exit\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a970c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb00e3bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

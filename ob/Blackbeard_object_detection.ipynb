{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0556d425",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################################\n",
    "# Project Name: BlackBeard\n",
    "# Created by: Parbin Darji, Will Fortenberry, Andrew Palmertree, Imanol  Perales, Justin Romanowski\n",
    "#\n",
    "# Script name: Train_object_detection.ipynb\n",
    "#\n",
    "# The face recognition code is based on the creator's code: Evan Juras\n",
    "# The script we edited was based on his google colab:\n",
    "# https://colab.research.google.com/github/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi/blob/master/Train_TFLite2_Object_Detction_Model.ipynb#scrollTo=fF8ysCfYKgTP\n",
    "# His github: \n",
    "# https://github.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi\n",
    "#\n",
    "# Editor of the script: Andrew Palmertree\n",
    "#\n",
    "# Date: March 9, 2024\n",
    "# Version: 1.0.0\n",
    "# \n",
    "# Requirments:\n",
    "#     - python 3.9.18\n",
    "#     - check the requirement.txt file for specific packages\n",
    "#\n",
    "# Description:\n",
    "#     The Train_object_detection script is for the BlackBeard project to be used on the server side to\n",
    "#     train an object detection model using custome data from roboflow.\n",
    "#\n",
    "#      Object list training: amazon logo, amazon delivery uniform, delivery car, fedex logo,\n",
    "#                   fedex uniform, package, person, safety vest, ups logo, ups uniform\n",
    "#                   usps logo, and usps delivery uniform\n",
    "#\n",
    "# Notes:\n",
    "#  We used the ssd-mobilenet-v2 model\n",
    "#  Linke to out roboflow data set:\n",
    "#  https://universe.roboflow.com/project-gnup6/blackbeard-object-detection-ksu\n",
    "#############################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101a4e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#============================================================================================\n",
    "# Import the necessary package libraries\n",
    "#============================================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1aefa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import pathlib\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import io\n",
    "import imageio\n",
    "import glob\n",
    "import scipy.misc\n",
    "import numpy as np\n",
    "from six import BytesIO\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from IPython.display import display, Javascript\n",
    "from IPython.display import Image as IPyImage\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "from object_detection.builders import model_builder\n",
    "from roboflow import Roboflow\n",
    "import requests\n",
    "import tarfile\n",
    "import re\n",
    "import cv2\n",
    "import sys\n",
    "import importlib.util\n",
    "from tensorflow.lite.python.interpreter import Interpreter\n",
    "import urllib.request\n",
    "import zipfile\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122ceec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0123e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the GPU on server to train the model\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        print(\"Found a GPU with the name:\", gpu)\n",
    "else:\n",
    "    print(\"Failed to detect a GPU.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476eabbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fad22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd \"C:\\Users\\andre\\CPE_4093\\ob\\main_content\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325db427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the tensorflow models repository if it doesn't already exist\n",
    "if \"models\" in pathlib.Path.cwd().parts:\n",
    "  while \"models\" in pathlib.Path.cwd().parts:\n",
    "    os.chdir('..')\n",
    "elif not pathlib.Path('models').exists():\n",
    "  !git clone --depth 1 https://github.com/tensorflow/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5976ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%bash\n",
    "# protoc\n",
    "#install the neccesary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3b26a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5228ed4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%bash\n",
    "\n",
    "#install the neccesary packages \n",
    "# only needed for the first time running \n",
    "\n",
    "# cd models/research/\n",
    "# protoc object_detection/protos/*.proto --python_out=.\n",
    "# cp object_detection/packages/tf2/setup.py .\n",
    "# python -m pip install --user ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8f654d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --user protobuf==3.20.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db67bf92",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d25012",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Downloading data from Roboflow\n",
    "\n",
    "# More package vest images\n",
    "rf = Roboflow(api_key=\"Kcuk1uPgEUza7o2ZTKhu\")\n",
    "project = rf.workspace(\"blackbeard\").project(\"blackbeard\")\n",
    "version = project.version(4).download(\"tfrecord\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad4ec47",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = r\"C:/Users/andre/CPE_4093/ob/main_content/BlackBeard-4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213c4ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bd9e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Update these TFRecord names from \"cells\" and \"cells_label_map\" to your files!\n",
    "test_record_fname = dataset + '/test/boxes.tfrecord'\n",
    "train_record_fname = dataset + '/train/boxes.tfrecord'\n",
    "label_map_pbtxt_fname = dataset + '/train/boxes_label_map.pbtxt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e498879a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the model name, pretrained checkpoint and base file variables for ssd-mobilenet-v2-fpnlite-320 \n",
    "model_name = 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8'\n",
    "pretrained_checkpoint = 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz'\n",
    "base_pipeline_file = 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.config'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa0db40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set training parameters for the model\n",
    "num_steps = 7200\n",
    "num_eval_steps = 250\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cb611c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the directory you want the model to be saved in\n",
    "dir = \"ssd-mobilenet-v2-fpnlite-320_with_vests8_1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d034cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2f7fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory path\n",
    "dir_path = fr\"C:\\Users\\andre\\CPE_4093\\ob\\main_content\\mymodel\\{dir}\"\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "if not os.path.exists(dir_path):\n",
    "    os.makedirs(dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c3c164",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd C:\\Users\\andre\\CPE_4093\\ob\\main_content\\mymodel\\{dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1dfb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL for the pretrained checkpoint\n",
    "download_tar = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/' + pretrained_checkpoint\n",
    "\n",
    "# Download the file using requests\n",
    "response = requests.get(download_tar)\n",
    "\n",
    "# Check if the request was successful (status code 200)\n",
    "if response.status_code == 200:\n",
    "    # Save the downloaded file\n",
    "    with open(pretrained_checkpoint, 'wb') as f:\n",
    "        f.write(response.content)\n",
    "\n",
    "    # Extract the downloaded file\n",
    "    tar = tarfile.open(pretrained_checkpoint)\n",
    "    tar.extractall()\n",
    "    tar.close()\n",
    "else:\n",
    "    print(\"Failed to download the file\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4a6154",
   "metadata": {},
   "outputs": [],
   "source": [
    "#download base training configuration file\n",
    "# URL for the base training configuration file\n",
    "download_config = 'https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/configs/tf2/' + base_pipeline_file\n",
    "\n",
    "# Send a GET request to download the configuration file\n",
    "response = requests.get(download_config)\n",
    "\n",
    "# Check if the request was successful (status code 200)\n",
    "if response.status_code == 200:\n",
    "    # Save the downloaded file\n",
    "    with open(base_pipeline_file, 'wb') as f:\n",
    "        f.write(response.content)\n",
    "else:\n",
    "    print(\"Failed to download the file\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887a3f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare the model base for ssd-mobilenet-v2-fpnlite-320\n",
    "pipeline_fname = fr\"C:\\\\Users\\\\andre\\\\CPE_4093\\\\ob\\\\main_content\\\\mymodel\\\\{dir}\\\\ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.config\"\n",
    "# fine_tune_checkpoint = fr'C:\\\\Users\\\\andre\\\\CPE_4093\\\\ob\\\\main_content\\\\mymodel\\\\{dir}\\\\ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8\\\\checkpoint\\\\ckpt-0'\n",
    "fine_tune_checkpoint = fr\"C:\\\\Users\\\\andre\\\\CPE_4093\\\\ob\\\\main_content\\\\training\\\\ssd-mobilenet-v2-fpnlite-320_with_vests8_1\\\\ckpt-8\"\n",
    "\n",
    "def get_num_classes(pbtxt_fname):\n",
    "    label_map = label_map_util.load_labelmap(pbtxt_fname)\n",
    "    categories = label_map_util.convert_label_map_to_categories(\n",
    "        label_map, max_num_classes=90, use_display_name=True)\n",
    "    category_index = label_map_util.create_category_index(categories)\n",
    "    return len(category_index.keys())\n",
    "num_classes = get_num_classes(label_map_pbtxt_fname)\n",
    "print(f\"Number of classes used {num_classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7f55dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify the model name, pipline file, and checkpoint path\n",
    "print(\"model name:\")\n",
    "print(model_name)\n",
    "print(\"\\npipline file: \")\n",
    "print(pipeline_fname)\n",
    "print(\"\\ncheckpoint file: \")\n",
    "print(fine_tune_checkpoint)\n",
    "\n",
    "print(\"\\ncurrent directory\")\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c76eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#write custom configuration file by slotting our dataset, model checkpoint, and training parameters into the base pipeline file\n",
    "\n",
    "%cd \"C:\\Users\\andre\\CPE_4093\\ob\\main_content\\mymodel\\{dir}\" \n",
    "\n",
    "print('writing custom configuration file')\n",
    "print(pipeline_fname)\n",
    "\n",
    "with open(pipeline_fname) as f:\n",
    "    s = f.read()\n",
    "with open('pipeline_file2.config', 'w') as f:\n",
    "    \n",
    "    # fine_tune_checkpoint\n",
    "    s = re.sub(r'fine_tune_checkpoint: \".*?\"',\n",
    "               'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint.replace('\\\\', r'\\\\\\\\')), s)\n",
    "    \n",
    "    # tfrecord files train and test.\n",
    "    s = re.sub(\n",
    "        r'(input_path: \".*?)(PATH_TO_BE_CONFIGURED/train)(.*?\")', 'input_path: \"{}\"'.format(train_record_fname.replace('\\\\', r'\\\\\\\\')), s)\n",
    "    s = re.sub(\n",
    "        r'(input_path: \".*?)(PATH_TO_BE_CONFIGURED/val)(.*?\")', 'input_path: \"{}\"'.format(test_record_fname.replace('\\\\', r'\\\\\\\\')), s)\n",
    "\n",
    "    # label_map_path\n",
    "    s = re.sub(\n",
    "        r'label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format(label_map_pbtxt_fname.replace('\\\\', r'\\\\\\\\')), s)\n",
    "\n",
    "    # Set training batch_size.\n",
    "    s = re.sub(r'batch_size: [0-9]+',\n",
    "               'batch_size: {}'.format(batch_size), s)\n",
    "\n",
    "    # Set training steps, num_steps\n",
    "    s = re.sub(r'num_steps: [0-9]+',\n",
    "               'num_steps: {}'.format(num_steps), s)\n",
    "    \n",
    "    # Set number of classes num_classes.\n",
    "    s = re.sub(r'num_classes: [0-9]+',\n",
    "               'num_classes: {}'.format(num_classes), s)\n",
    "    \n",
    "    # fine-tune checkpoint type\n",
    "    s = re.sub(\n",
    "        r'fine_tune_checkpoint_type: \"classification\"', 'fine_tune_checkpoint_type: \"{}\"'.format('detection'), s)\n",
    "        \n",
    "    f.write(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00685b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!type pipeline_file2.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654eff0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_file = fr\"C:\\Users\\andre\\CPE_4093\\ob\\main_content\\mymodel\\{dir}\\pipeline_file2.config\"\n",
    "model_dir = fr\"C:\\Users\\andre\\CPE_4093\\ob\\main_content\\training\\{dir}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5df033",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pipeline_file)\n",
    "print(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c506132",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_DIR'] = 'C:\\\\Users\\\\andre\\\\anaconda3\\\\pkgs\\\\cudatoolkit-11.2.2-h933977f_10\\\\DLLs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f679bc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_dir = os.getenv('CUDA_DIR')\n",
    "print(cuda_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b909ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "## train the model to a checkpoint file\n",
    "!python \"C:\\\\Users\\\\andre\\\\CPE_4093\\\\ob\\\\content\\\\models\\\\research\\\\object_detection\\\\model_main_tf2.py\" \\\n",
    "    --pipeline_config_path={pipeline_file} \\\n",
    "    --model_dir={model_dir} \\\n",
    "    --alsologtostderr \\\n",
    "    --num_train_steps={num_steps} \\\n",
    "    --sample_1_of_n_eval_examples=1 \\\n",
    "    --num_eval_steps={num_eval_steps}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08c2d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## see where our model saved weights are located\n",
    "print(os.listdir(fr\"C:\\Users\\andre\\CPE_4093\\ob\\main_content\\training\\{dir}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e3a2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create a directory to store the tensorflow and tflite model files\n",
    "# Define the directory path\n",
    "dir_path = fr\"C:\\Users\\andre\\CPE_4093\\ob\\main_content\\training\\{dir}\\custom_model_{dir}\"\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "if not os.path.exists(dir_path):\n",
    "    os.makedirs(dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eaeb093",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Export the saved checkpoint file to a tensorflow graph\n",
    "output_directory = f'C:\\\\Users\\\\andre\\\\CPE_4093\\\\ob\\\\main_content\\\\training\\\\{dir}\\\\custom_model_{dir}'\n",
    "\n",
    "last_model_path = f'C:\\\\Users\\\\andre\\\\CPE_4093\\\\ob\\\\main_content\\\\training\\\\{dir}\\\\'\n",
    "\n",
    "!python  \"C:\\\\Users\\\\andre\\\\CPE_4093\\\\ob\\\\content\\\\models\\\\research\\\\object_detection\\\\export_tflite_graph_tf2.py\" \\\n",
    "    --trained_checkpoint_dir {last_model_path} \\\n",
    "    --output_directory {output_directory} \\\n",
    "    --pipeline_config_path {pipeline_file}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e8a900",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert exported graph file into TFLite model file\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(fr\"C:\\Users\\andre\\CPE_4093\\ob\\main_content\\training\\{dir}\\custom_model_{dir}\\saved_model\")\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open(fr\"C:\\Users\\andre\\CPE_4093\\ob\\main_content\\training\\{dir}\\custom_model_{dir}\\detect.tflite\", 'wb') as f:\n",
    "  f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb1184d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create label file\n",
    "# Define the file path\n",
    "file_path = fr\"C:\\Users\\andre\\CPE_4093\\ob\\main_content\\training\\{dir}\\custom_model_{dir}\\labelmap.txt\"\n",
    "\n",
    "# Define the content\n",
    "content = \"\"\"amazon\n",
    "amazon_uniform\n",
    "delivery_car\n",
    "fedex\n",
    "fedex_uniform\n",
    "package\n",
    "person\n",
    "safety_vest\n",
    "ups\n",
    "ups_uniform\n",
    "usps\n",
    "usps_uniform\n",
    "\"\"\"\n",
    "\n",
    "# Check if the file exists\n",
    "if not os.path.exists(file_path):\n",
    "    # If the file doesn't exist, create it and write the content\n",
    "    with open(file_path, 'w') as f:\n",
    "        f.write(content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad0d258",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create label map file\n",
    "# Define the file path\n",
    "file_path_pbtxt = fr\"C:\\Users\\andre\\CPE_4093\\ob\\main_content\\training\\{dir}\\custom_model_{dir}\\label_map.pbtxt\"\n",
    "\n",
    "# Define the content\n",
    "content = \"\"\"item {\n",
    "  id: 1\n",
    "  name: 'amazon'\n",
    "}\n",
    "\n",
    "item {\n",
    "  id: 2\n",
    "  name: 'amazon uniform'\n",
    "}\n",
    "\n",
    "item {\n",
    "  id: 3\n",
    "  name: 'delivery car'\n",
    "}\n",
    "\n",
    "item {\n",
    "  id: 4\n",
    "  name: 'fedex'\n",
    "}\n",
    "\n",
    "item {\n",
    "  id: 5\n",
    "  name: 'fedex uniform'\n",
    "}\n",
    "\n",
    "item {\n",
    "  id: 6\n",
    "  name: 'package'\n",
    "}\n",
    "\n",
    "item {\n",
    "  id: 7\n",
    "  name: 'person'\n",
    "}\n",
    "\n",
    "item {\n",
    "  id: 8\n",
    "  name: 'safety vest'\n",
    "}\n",
    "\n",
    "item {\n",
    "  id: 9\n",
    "  name: 'ups'\n",
    "}\n",
    "\n",
    "item {\n",
    "  id: 10\n",
    "  name: 'ups uniform'\n",
    "}\n",
    "\n",
    "item {\n",
    "  id: 11\n",
    "  name: 'usps'\n",
    "}\n",
    "\n",
    "item {\n",
    "  id: 12\n",
    "  name: 'usps uniform'\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "if not os.path.exists(file_path_pbtxt):\n",
    "    # If the file doesn't exist, create it and write the content\n",
    "    with open(file_path_pbtxt, 'w') as f:\n",
    "        f.write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d407d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Download test images\n",
    "# Define the directory path\n",
    "dir_path = 'C:\\\\Users\\\\andre\\\\CPE_4093\\\\ob\\\\main_content\\\\test_images6'\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "if not os.path.exists(dir_path):\n",
    "    os.makedirs(dir_path)\n",
    "\n",
    "# Change the current directory to the newly created directory\n",
    "os.chdir(dir_path)\n",
    "\n",
    "# Define the URL of the file to be downloaded\n",
    "url = \"https://app.roboflow.com/ds/lwd70Iqeq2?key=0DI02oVWZi\"\n",
    "\n",
    "# Define the local filename\n",
    "filename = \"roboflow.zip\"\n",
    "filename2 = \"test_images\"\n",
    "\n",
    "# Download the file only if it doesn't already exist\n",
    "if not os.path.exists(filename2):\n",
    "    urllib.request.urlretrieve(url, filename)\n",
    "\n",
    "    # Unzip the file\n",
    "    with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
    "        zip_ref.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7651ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Script to run custom TFLite model on test images to detect objects\n",
    "# Source: https://github.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi/blob/master/TFLite_detection_image.py\n",
    "\n",
    "### Define function for inferencing with TFLite model and displaying results\n",
    "\n",
    "def tflite_detect_images(modelpath, imgpath, lblpath, min_conf=0.5, num_test_images=10, savepath=r\"C:\\Users\\andre\\CPE_4093\\ob\\main_content\\results\", txt_only=False):\n",
    "\n",
    "  # Grab filenames of all images in test folder\n",
    "  images = glob.glob(imgpath + '/*.jpg') + glob.glob(imgpath + '/*.JPG') + glob.glob(imgpath + '/*.png') + glob.glob(imgpath + '/*.bmp')\n",
    "\n",
    "  # Load the label map into memory\n",
    "  with open(lblpath, 'r') as f:\n",
    "      labels = [line.strip() for line in f.readlines()]\n",
    "\n",
    "  # Load the Tensorflow Lite model into memory\n",
    "  interpreter = Interpreter(model_path=modelpath)\n",
    "  interpreter.allocate_tensors()\n",
    "\n",
    "  # Get output details\n",
    "  output_details = interpreter.get_output_details()\n",
    "\n",
    "  # Print output details\n",
    "  print(output_details)\n",
    "\n",
    "  # Get model details\n",
    "  input_details = interpreter.get_input_details()\n",
    "  output_details = interpreter.get_output_details()\n",
    "  height = input_details[0]['shape'][1]\n",
    "  width = input_details[0]['shape'][2]\n",
    "\n",
    "  float_input = (input_details[0]['dtype'] == np.float32)\n",
    "\n",
    "  input_mean = 127.5\n",
    "  input_std = 127.5\n",
    "\n",
    "  # Randomly select test images\n",
    "  images_to_test = random.sample(images, num_test_images)\n",
    "\n",
    "  # Loop over every image and perform detection\n",
    "  for image_path in images_to_test:\n",
    "\n",
    "      # Load image and resize to expected shape [1xHxWx3]\n",
    "      image = cv2.imread(image_path)\n",
    "      image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "      imH, imW, _ = image.shape\n",
    "      image_resized = cv2.resize(image_rgb, (width, height))\n",
    "      input_data = np.expand_dims(image_resized, axis=0)\n",
    "\n",
    "      # Normalize pixel values if using a floating model (i.e. if model is non-quantized)\n",
    "      if float_input:\n",
    "          input_data = (np.float32(input_data) - input_mean) / input_std\n",
    "\n",
    "      # Perform the actual detection by running the model with the image as input\n",
    "      interpreter.set_tensor(input_details[0]['index'],input_data)\n",
    "      interpreter.invoke()\n",
    "\n",
    "      # Retrieve detection results\n",
    "      boxes = interpreter.get_tensor(output_details[1]['index'])[0] # Bounding box coordinates of detected objects\n",
    "      classes = interpreter.get_tensor(output_details[3]['index'])[0] # Class index of detected objects\n",
    "      scores = interpreter.get_tensor(output_details[0]['index'])[0] # Confidence of detected objects\n",
    "      print(scores)\n",
    "      detections = []\n",
    "\n",
    "      # Loop over all detections and draw detection box if confidence is above minimum threshold\n",
    "      for i in range(len(scores)):\n",
    "          if ((scores[i] > min_conf) and (scores[i] <= 1.0)):\n",
    "\n",
    "              # Get bounding box coordinates and draw box\n",
    "              # Interpreter can return coordinates that are outside of image dimensions, need to force them to be within image using max() and min()\n",
    "              ymin = int(max(1,(boxes[i][0] * imH)))\n",
    "              xmin = int(max(1,(boxes[i][1] * imW)))\n",
    "              ymax = int(min(imH,(boxes[i][2] * imH)))\n",
    "              xmax = int(min(imW,(boxes[i][3] * imW)))\n",
    "\n",
    "              cv2.rectangle(image, (xmin,ymin), (xmax,ymax), (10, 255, 0), 2)\n",
    "\n",
    "              # Draw label\n",
    "              object_name = labels[int(classes[i])] # Look up object name from \"labels\" array using class index\n",
    "              label = '%s: %d%%' % (object_name, int(scores[i]*100)) # Example: 'person: 72%'\n",
    "              labelSize, baseLine = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2) # Get font size\n",
    "              label_ymin = max(ymin, labelSize[1] + 10) # Make sure not to draw label too close to top of window\n",
    "              cv2.rectangle(image, (xmin, label_ymin-labelSize[1]-10), (xmin+labelSize[0], label_ymin+baseLine-10), (255, 255, 255), cv2.FILLED) # Draw white box to put label text in\n",
    "              cv2.putText(image, label, (xmin, label_ymin-7), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2) # Draw label text\n",
    "\n",
    "              detections.append([object_name, scores[i], xmin, ymin, xmax, ymax])\n",
    "\n",
    "\n",
    "      # All the results have been drawn on the image, now display the image\n",
    "      if txt_only == False: # \"text_only\" controls whether we want to display the image results or just save them in .txt files\n",
    "        image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "        plt.figure(figsize=(12,16))\n",
    "        plt.imshow(image)\n",
    "        plt.show()\n",
    "\n",
    "      # Save detection results in .txt files (for calculating mAP)\n",
    "      elif txt_only == True:\n",
    "\n",
    "        # Get filenames and paths\n",
    "        image_fn = os.path.basename(image_path)\n",
    "        base_fn, ext = os.path.splitext(image_fn)\n",
    "        txt_result_fn = base_fn +'.txt'\n",
    "        txt_savepath = os.path.join(savepath, txt_result_fn)\n",
    "\n",
    "        # Write results to text file\n",
    "        # (Using format defined by https://github.com/Cartucho/mAP, which will make it easy to calculate mAP)\n",
    "        with open(txt_savepath,'w') as f:\n",
    "            for detection in detections:\n",
    "                f.write('%s %.4f %d %d %d %d\\n' % (detection[0], detection[1], detection[2], detection[3], detection[4], detection[5]))\n",
    "\n",
    "  return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6e2824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up variables for running user's model\n",
    "PATH_TO_IMAGES=r\"C:\\Users\\andre\\CPE_4093\\ob\\main_content\\test_images6\\test\"  # Path to test images folder\n",
    "PATH_TO_MODEL=fr\"C:\\Users\\andre\\CPE_4093\\ob\\main_content\\training\\{dir}\\custom_model_{dir}\\detect.tflite\"   # Path to .tflite model file\n",
    "PATH_TO_LABELS=fr\"C:\\Users\\andre\\CPE_4093\\ob\\main_content\\training\\{dir}\\custom_model_{dir}\\labelmap.txt\"   # Path to labelmap.txt file\n",
    "min_conf_threshold=0.5   # Confidence threshold (try changing this to 0.01 if you don't see any detection results)\n",
    "images_to_test = 100   # Number of images to run detection on\n",
    "\n",
    "# Run inferencing function!\n",
    "tflite_detect_images(PATH_TO_MODEL, PATH_TO_IMAGES, PATH_TO_LABELS, min_conf_threshold, images_to_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112938b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac116d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Object recognition quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faca9346",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of all images in train directory\n",
    "\n",
    "## This is for object classification\n",
    "image_path = r\"C:\\Users\\andre\\CPE_4093\\ob\\main_content\\test_images4\\train\"\n",
    "\n",
    "jpg_file_list = glob.glob(image_path + '/*.jpg')\n",
    "JPG_file_list = glob.glob(image_path + '/*.JPG')\n",
    "png_file_list = glob.glob(image_path + '/*.png')\n",
    "bmp_file_list = glob.glob(image_path + '/*.bmp')\n",
    "\n",
    "quant_image_list = jpg_file_list + JPG_file_list + png_file_list + bmp_file_list\n",
    "\n",
    "interpreter = Interpreter(model_path=PATH_TO_MODEL)\n",
    "interpreter.allocate_tensors()\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "height = input_details[0]['shape'][1]\n",
    "width = input_details[0]['shape'][2]\n",
    "\n",
    "\n",
    "# A generator that provides a representative dataset\n",
    "def representative_data_gen():\n",
    "    dataset_list = quant_image_list\n",
    "    quant_num = 300\n",
    "    for i in range(quant_num):\n",
    "        pick_me = random.choice(dataset_list)\n",
    "        image = tf.io.read_file(pick_me)\n",
    "\n",
    "        if pick_me.endswith('.jpg') or pick_me.endswith('.JPG'):\n",
    "            image = tf.io.decode_jpeg(image, channels=3)\n",
    "        elif pick_me.endswith('.png'):\n",
    "            image = tf.io.decode_png(image, channels=3)\n",
    "        elif pick_me.endswith('.bmp'):\n",
    "            image = tf.io.decode_bmp(image, channels=3)\n",
    "\n",
    "        image = tf.image.resize(image, [width, height])\n",
    "        image = tf.cast(image / 255., tf.float32)\n",
    "        image = tf.expand_dims(image, 0)\n",
    "        yield [image]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54ab4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize converter module\n",
    "\n",
    "## Object Recognition model\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(fr\"C:\\Users\\andre\\CPE_4093\\ob\\main_content\\training\\{dir}\\custom_model_{dir}\\saved_model\")\n",
    "\n",
    "## This enables quantization\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "# This sets the representative dataset for quantization\n",
    "converter.representative_dataset = representative_data_gen\n",
    "# This ensures that if any ops can't be quantized, the converter throws an error\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "# For full integer quantization, though supported types defaults to int8 only, we explicitly declare it for clarity.\n",
    "converter.target_spec.supported_types = [tf.int8]\n",
    "# These set the input tensors to uint8 and output tensors to float32\n",
    "converter.inference_input_type = tf.uint8\n",
    "converter.inference_output_type = tf.float32\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the quantized model to a file\n",
    "with open(fr\"C:\\Users\\andre\\CPE_4093\\ob\\main_content\\training\\{dir}\\custom_model_{dir}\\{dir}_quant.tflite\", 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48770d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216382d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739f57c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
